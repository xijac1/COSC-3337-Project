{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from src.networks.graph_builder import build_citation_graph, build_coauthorship_graph\n",
    "from src.networks.metrics import calculate_centralities\n",
    "\n",
    "# Load Data\n",
    "# citations_df = pd.read_parquet(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371c0caa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# DBLP Network Analysis: Collaboration, Communities, and Influence\\n\",\n",
    "        \"\\n\",\n",
    "        \"**Team Member:** Ai Nhien To  \\n\",\n",
    "        \"**Task:** Network Analysis (Citation & Co-authorship Graphs)  \\n\",\n",
    "        \"**Date:** December 4, 2025\\n\",\n",
    "        \"\\n\",\n",
    "        \"This notebook performs network analysis on the cleaned DBLP Parquet datasets:\\n\",\n",
    "        \"\\n\",\n",
    "        \"- Build **citation** (directed) and **co-authorship** (undirected) graphs  \\n\",\n",
    "        \"- Compute basic **graph statistics** (nodes, edges, density, components)  \\n\",\n",
    "        \"- Compute **centrality metrics** (degree, PageRank, betweenness)  \\n\",\n",
    "        \"- Detect **communities** (Louvain on co-authorship graph)  \\n\",\n",
    "        \"- Explore **temporal evolution** based on publication year  \\n\",\n",
    "        \"- Generate **summary tables and visualizations** for the final report\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 1. Imports & configuration\\n\",\n",
    "        \"\\n\",\n",
    "        \"import pandas as pd\\n\",\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import networkx as nx\\n\",\n",
    "        \"from pathlib import Path\\n\",\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"\\n\",\n",
    "        \"plt.rcParams[\\\"figure.figsize\\\"] = (8, 5)\\n\",\n",
    "        \"\\n\",\n",
    "        \"DATA_DIR = Path(\\\"../data/parquet\\\")\\n\",\n",
    "        \"OUTPUT_DIR = Path(\\\"../data/derived\\\")\\n\",\n",
    "        \"OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"DATA_DIR:\\\", DATA_DIR.resolve())\\n\",\n",
    "        \"print(\\\"OUTPUT_DIR:\\\", OUTPUT_DIR.resolve())\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 2. Load Parquet datasets\\n\",\n",
    "        \"# Paths and filenames are based on the project structure and data dictionary.\\n\",\n",
    "        \"\\n\",\n",
    "        \"papers = pd.read_parquet(DATA_DIR / \\\"papers\\\")\\n\",\n",
    "        \"citations = pd.read_parquet(DATA_DIR / \\\"citations\\\")\\n\",\n",
    "        \"coauth = pd.read_parquet(DATA_DIR / \\\"coauthorships\\\")\\n\",\n",
    "        \"authorships = pd.read_parquet(DATA_DIR / \\\"authorships\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"papers:\\\", papers.shape)\\n\",\n",
    "        \"print(\\\"citations:\\\", citations.shape)\\n\",\n",
    "        \"print(\\\"coauthorships:\\\", coauth.shape)\\n\",\n",
    "        \"print(\\\"authorships:\\\", authorships.shape)\\n\",\n",
    "        \"\\n\",\n",
    "        \"display(papers.head())\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 3. Quick sanity checks similar to data profiling\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"\\\\nPapers year stats:\\\")\\n\",\n",
    "        \"if \\\"year\\\" in papers.columns:\\n\",\n",
    "        \"    display(papers[[\\\"year\\\"]].describe())\\n\",\n",
    "        \"else:\\n\",\n",
    "        \"    print(\\\"No 'year' column found in papers table.\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"\\\\nMissing values ratio (citations):\\\")\\n\",\n",
    "        \"display(citations.isna().mean())\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"\\\\nMissing values ratio (coauthorships):\\\")\\n\",\n",
    "        \"display(coauth.isna().mean())\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Build graphs\\n\",\n",
    "        \"\\n\",\n",
    "        \"We construct:\\n\",\n",
    "        \"- A **directed citation graph** where nodes are papers and edges (src_id → dst_id) mean *paper src cites paper dst*  \\n\",\n",
    "        \"- An **undirected co-authorship graph** where nodes are normalized author names and edges connect authors that co-wrote at least one paper\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 4. Build citation graph (directed)\\n\",\n",
    "        \"# From data dictionary: src_id (citing), dst_id (cited)\\n\",\n",
    "        \"\\n\",\n",
    "        \"CITING_COL = \\\"src_id\\\"\\n\",\n",
    "        \"CITED_COL = \\\"dst_id\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"assert CITING_COL in citations.columns and CITED_COL in citations.columns, \\\"src_id/dst_id not found in citations table.\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"G_cit = nx.from_pandas_edgelist(\\n\",\n",
    "        \"    citations,\\n\",\n",
    "        \"    source=CITING_COL,\\n\",\n",
    "        \"    target=CITED_COL,\\n\",\n",
    "        \"    create_using=nx.DiGraph()\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Citation graph:\\\")\\n\",\n",
    "        \"print(\\\"  # Nodes:\\\", G_cit.number_of_nodes())\\n\",\n",
    "        \"print(\\\"  # Edges:\\\", G_cit.number_of_edges())\\n\",\n",
    "        \"print(\\\"  Density:\\\", nx.density(G_cit))\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 5. Basic citation graph profiling: in-/out-degree distributions\\n\",\n",
    "        \"\\n\",\n",
    "        \"in_degrees = [d for _, d in G_cit.in_degree()]\\n\",\n",
    "        \"out_degrees = [d for _, d in G_cit.out_degree()]\\n\",\n",
    "        \"\\n\",\n",
    "        \"cit_summary = pd.DataFrame({\\n\",\n",
    "        \"    \\\"in_degree\\\": in_degrees,\\n\",\n",
    "        \"    \\\"out_degree\\\": out_degrees\\n\",\n",
    "        \"})\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Citation degree summary:\\\")\\n\",\n",
    "        \"display(cit_summary.describe())\\n\",\n",
    "        \"\\n\",\n",
    "        \"# In-degree histogram (log y-scale)\\n\",\n",
    "        \"plt.hist(in_degrees, bins=50)\\n\",\n",
    "        \"plt.yscale(\\\"log\\\")\\n\",\n",
    "        \"plt.title(\\\"Citation Graph In-Degree Distribution\\\")\\n\",\n",
    "        \"plt.xlabel(\\\"In-degree\\\")\\n\",\n",
    "        \"plt.ylabel(\\\"Count (log scale)\\\")\\n\",\n",
    "        \"plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Out-degree histogram (log y-scale)\\n\",\n",
    "        \"plt.hist(out_degrees, bins=50)\\n\",\n",
    "        \"plt.yscale(\\\"log\\\")\\n\",\n",
    "        \"plt.title(\\\"Citation Graph Out-Degree Distribution\\\")\\n\",\n",
    "        \"plt.xlabel(\\\"Out-degree\\\")\\n\",\n",
    "        \"plt.ylabel(\\\"Count (log scale)\\\")\\n\",\n",
    "        \"plt.show()\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 6. Build co-authorship graph (undirected)\\n\",\n",
    "        \"# From data dictionary: author1_norm, author2_norm\\n\",\n",
    "        \"\\n\",\n",
    "        \"A1_COL = \\\"author1_norm\\\"\\n\",\n",
    "        \"A2_COL = \\\"author2_norm\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"assert A1_COL in coauth.columns and A2_COL in coauth.columns, \\\"author1_norm/author2_norm not found in coauthorships table.\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"G_co = nx.from_pandas_edgelist(\\n\",\n",
    "        \"    coauth,\\n\",\n",
    "        \"    source=A1_COL,\\n\",\n",
    "        \"    target=A2_COL,\\n\",\n",
    "        \"    create_using=nx.Graph()\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Co-authorship graph:\\\")\\n\",\n",
    "        \"print(\\\"  # Nodes:\\\", G_co.number_of_nodes())\\n\",\n",
    "        \"print(\\\"  # Edges:\\\", G_co.number_of_edges())\\n\",\n",
    "        \"print(\\\"  Density:\\\", nx.density(G_co))\\n\",\n",
    "        \"\\n\",\n",
    "        \"components = list(nx.connected_components(G_co))\\n\",\n",
    "        \"giant_component = max(components, key=len) if components else set()\\n\",\n",
    "        \"print(\\\"  # Connected components:\\\", len(components))\\n\",\n",
    "        \"print(\\\"  Giant component size:\\\", len(giant_component))\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 7. Co-authorship degree profiling\\n\",\n",
    "        \"\\n\",\n",
    "        \"co_degrees = [d for _, d in G_co.degree()]\\n\",\n",
    "        \"co_deg_series = pd.Series(co_degrees, name=\\\"degree\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Co-authorship degree summary:\\\")\\n\",\n",
    "        \"display(co_deg_series.describe())\\n\",\n",
    "        \"\\n\",\n",
    "        \"plt.hist(co_degrees, bins=50)\\n\",\n",
    "        \"plt.yscale(\\\"log\\\")\\n\",\n",
    "        \"plt.title(\\\"Co-authorship Graph Degree Distribution\\\")\\n\",\n",
    "        \"plt.xlabel(\\\"Degree\\\")\\n\",\n",
    "        \"plt.ylabel(\\\"Count (log scale)\\\")\\n\",\n",
    "        \"plt.show()\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Centrality metrics\\n\",\n",
    "        \"\\n\",\n",
    "        \"We compute:\\n\",\n",
    "        \"- **Citation graph**: in-degree, out-degree, PageRank, betweenness  \\n\",\n",
    "        \"- **Co-authorship graph**: degree, betweenness  \\n\",\n",
    "        \"\\n\",\n",
    "        \"Then join with metadata (titles, years, venues) where applicable.\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 8. Centrality metrics for citation graph\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Computing PageRank for citation graph...\\\")\\n\",\n",
    "        \"pagerank = nx.pagerank(G_cit)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Computing betweenness centrality (approximate) for citation graph...\\\")\\n\",\n",
    "        \"bet_cit = nx.betweenness_centrality(G_cit, k=1000, seed=42)\\n\",\n",
    "        \"\\n\",\n",
    "        \"deg_in = dict(G_cit.in_degree())\\n\",\n",
    "        \"deg_out = dict(G_cit.out_degree())\\n\",\n",
    "        \"\\n\",\n",
    "        \"# According to data dictionary, paper primary key is `id`\\n\",\n",
    "        \"PAPER_ID_COL = \\\"id\\\"\\n\",\n",
    "        \"assert PAPER_ID_COL in papers.columns, \\\"Column 'id' not found in papers table.\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"cit_metrics = pd.DataFrame({\\n\",\n",
    "        \"    PAPER_ID_COL: list(G_cit.nodes()),\\n\",\n",
    "        \"    \\\"deg_in\\\": [deg_in[n] for n in G_cit.nodes()],\\n\",\n",
    "        \"    \\\"deg_out\\\": [deg_out[n] for n in G_cit.nodes()],\\n\",\n",
    "        \"    \\\"pagerank\\\": [pagerank[n] for n in G_cit.nodes()],\\n\",\n",
    "        \"    \\\"betweenness\\\": [bet_cit[n] for n in G_cit.nodes()]\\n\",\n",
    "        \"})\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Join with paper metadata: id, title, year, venue if present\\n\",\n",
    "        \"meta_cols = [col for col in [\\\"id\\\", \\\"title\\\", \\\"year\\\", \\\"venue\\\"] if col in papers.columns]\\n\",\n",
    "        \"cit_metrics = cit_metrics.merge(papers[meta_cols], on=PAPER_ID_COL, how=\\\"left\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Top 10 papers by PageRank:\\\")\\n\",\n",
    "        \"display(cit_metrics.sort_values(\\\"pagerank\\\", ascending=False).head(10))\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 9. Centrality metrics for co-authorship graph\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Computing betweenness centrality (approximate) for co-authorship graph...\\\")\\n\",\n",
    "        \"bet_co = nx.betweenness_centrality(G_co, k=1000, seed=42)\\n\",\n",
    "        \"\\n\",\n",
    "        \"deg_co = dict(G_co.degree())\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Nodes are normalized author names (author_norm strings)\\n\",\n",
    "        \"co_metrics = pd.DataFrame({\\n\",\n",
    "        \"    \\\"author_norm\\\": list(G_co.nodes()),\\n\",\n",
    "        \"    \\\"degree\\\": [deg_co[n] for n in G_co.nodes()],\\n\",\n",
    "        \"    \\\"betweenness\\\": [bet_co[n] for n in G_co.nodes()]\\n\",\n",
    "        \"})\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Top 10 authors by degree:\\\")\\n\",\n",
    "        \"display(co_metrics.sort_values(\\\"degree\\\", ascending=False).head(10))\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Community detection (Louvain) on co-authorship graph\\n\",\n",
    "        \"\\n\",\n",
    "        \"We apply Louvain to detect collaboration communities among authors (using normalized names).\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 10. Community detection (Louvain)\\n\",\n",
    "        \"\\n\",\n",
    "        \"try:\\n\",\n",
    "        \"    import community as community_louvain  # python-louvain\\n\",\n",
    "        \"except ImportError as e:\\n\",\n",
    "        \"    raise ImportError(\\n\",\n",
    "        \"        \\\"python-louvain is required. Install with `pip install python-louvain`.\\\"\\n\",\n",
    "        \"    ) from e\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Running Louvain community detection on co-authorship graph...\\\")\\n\",\n",
    "        \"partition = community_louvain.best_partition(G_co)\\n\",\n",
    "        \"\\n\",\n",
    "        \"co_comm = pd.DataFrame({\\n\",\n",
    "        \"    \\\"author_norm\\\": list(partition.keys()),\\n\",\n",
    "        \"    \\\"community\\\": list(partition.values())\\n\",\n",
    "        \"})\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Top 10 communities by size:\\\")\\n\",\n",
    "        \"display(co_comm[\\\"community\\\"].value_counts().head(10))\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Merge with centrality metrics\\n\",\n",
    "        \"co_full = co_metrics.merge(co_comm, on=\\\"author_norm\\\", how=\\\"left\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Community-level stats (top 10 by size):\\\")\\n\",\n",
    "        \"community_stats = co_full.groupby(\\\"community\\\")[\\\"degree\\\"].agg([\\\"count\\\", \\\"mean\\\"]).sort_values(\\\"count\\\", ascending=False)\\n\",\n",
    "        \"display(community_stats.head(10))\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Temporal analysis\\n\",\n",
    "        \"\\n\",\n",
    "        \"We use **paper years** and **citation years** to explore evolution over time.\\n\",\n",
    "        \"- Papers: `year` (validated 1900–2030)\\n\",\n",
    "        \"- Citations: `src_year` (year of citing paper)\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 11. Temporal bins for papers\\n\",\n",
    "        \"\\n\",\n",
    "        \"if \\\"year\\\" not in papers.columns:\\n\",\n",
    "        \"    raise ValueError(\\\"Expected a 'year' column in papers table for temporal analysis.\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"papers = papers.copy()\\n\",\n",
    "        \"papers[\\\"year_bin\\\"] = (papers[\\\"year\\\"] // 5) * 5  # 5-year bins: 1900, 1905, ...\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Year bin distribution (papers):\\\")\\n\",\n",
    "        \"display(papers[\\\"year_bin\\\"].value_counts().sort_index())\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 12. Citations per time bin\\n\",\n",
    "        \"# Option 1: use src_year directly from citations (year of citing paper)\\n\",\n",
    "        \"\\n\",\n",
    "        \"if \\\"src_year\\\" in citations.columns:\\n\",\n",
    "        \"    citations = citations.copy()\\n\",\n",
    "        \"    citations[\\\"src_year_bin\\\"] = (citations[\\\"src_year\\\"] // 5) * 5\\n\",\n",
    "        \"    cit_by_src_bin = citations[\\\"src_year_bin\\\"].value_counts().sort_index()\\n\",\n",
    "        \"    print(\\\"Citations by 5-year bin (src_year):\\\")\\n\",\n",
    "        \"    display(cit_by_src_bin)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    cit_by_src_bin.plot(kind=\\\"bar\\\")\\n\",\n",
    "        \"    plt.title(\\\"Number of Citations by 5-Year Bin (based on citing paper src_year)\\\")\\n\",\n",
    "        \"    plt.xlabel(\\\"src_year bin\\\")\\n\",\n",
    "        \"    plt.ylabel(\\\"Number of citations\\\")\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"else:\\n\",\n",
    "        \"    print(\\\"Column 'src_year' not found in citations; skipping src_year-based temporal plot.\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Option 2: use cited paper year_bin (join citations.dst_id -> papers.id)\\n\",\n",
    "        \"\\n\",\n",
    "        \"cit_with_cited_year = citations.merge(\\n\",\n",
    "        \"    papers[[\\\"id\\\", \\\"year_bin\\\"]],\\n\",\n",
    "        \"    left_on=CITED_COL,\\n\",        \n",
    "        \"    right_on=\\\"id\\\",\\n\",\n",
    "        \"    how=\\\"left\\\"\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"cit_by_cited_bin = cit_with_cited_year[\\\"year_bin\\\"].value_counts().sort_index()\\n\",\n",
    "        \"print(\\\"Citations by 5-year bin (based on cited paper year_bin):\\\")\\n\",\n",
    "        \"display(cit_by_cited_bin)\\n\",\n",
    "        \"\\n\",\n",
    "        \"cit_by_cited_bin.plot(kind=\\\"bar\\\")\\n\",\n",
    "        \"plt.title(\\\"Number of Citations by 5-Year Bin (based on cited paper year)\\\")\\n\",\n",
    "        \"plt.xlabel(\\\"cited paper year_bin\\\")\\n\",\n",
    "        \"plt.ylabel(\\\"Number of citations\\\")\\n\",\n",
    "        \"plt.tight_layout()\\n\",\n",
    "        \"plt.show()\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Network visualizations\\n\",\n",
    "        \"\\n\",\n",
    "        \"We visualize a small subgraph of the citation network around the most influential papers (by PageRank).\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 13. Visualization of a citation subgraph (top papers by PageRank)\\n\",\n",
    "        \"\\n\",\n",
    "        \"TOP_K = 100  # number of top papers to include\\n\",\n",
    "        \"\\n\",\n",
    "        \"top_papers = cit_metrics.sort_values(\\\"pagerank\\\", ascending=False)[PAPER_ID_COL].head(TOP_K)\\n\",\n",
    "        \"subG = G_cit.subgraph(top_papers)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Subgraph nodes:\\\", subG.number_of_nodes())\\n\",\n",
    "        \"print(\\\"Subgraph edges:\\\", subG.number_of_edges())\\n\",\n",
    "        \"\\n\",\n",
    "        \"pos = nx.spring_layout(subG, k=0.15, iterations=30, seed=42)\\n\",\n",
    "        \"\\n\",\n",
    "        \"plt.figure(figsize=(8, 8))\\n\",\n",
    "        \"nx.draw_networkx_nodes(subG, pos, node_size=30)\\n\",\n",
    "        \"nx.draw_networkx_edges(subG, pos, alpha=0.2)\\n\",\n",
    "        \"plt.title(\\\"Citation Subgraph (Top 100 Papers by PageRank)\\\")\\n\",\n",
    "        \"plt.axis(\\\"off\\\")\\n\",\n",
    "        \"plt.show()\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# 14. Save summary tables for integration with other phases\\n\",\n",
    "        \"\\n\",\n",
    "        \"cit_metrics.to_csv(OUTPUT_DIR / \\\"citation_centrality_metrics.csv\\\", index=False)\\n\",\n",
    "        \"co_full.to_csv(OUTPUT_DIR / \\\"coauthor_centrality_communities.csv\\\", index=False)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Saved:\\\")\\n\",\n",
    "        \"print(\\\"  -\\\", (OUTPUT_DIR / \\\"citation_centrality_metrics.csv\\\").resolve())\\n\",\n",
    "        \"print(\\\"  -\\\", (OUTPUT_DIR / \\\"coauthor_centrality_communities.csv\\\").resolve())\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Summary of findings (to refine later)\\n\",\n",
    "        \"\\n\",\n",
    "        \"- The citation graph contains **X** papers and **Y** citation edges with a sparse, heavy-tailed degree distribution.  \\n\",\n",
    "        \"- A small set of papers have extremely high in-degree/PageRank, indicating strong influence in the field.  \\n\",\n",
    "        \"- The co-authorship graph exhibits a large giant component and multiple collaboration communities discovered by Louvain.  \\n\",\n",
    "        \"- Community-level statistics suggest that some communities are highly collaborative (high average degree) while others are more sparse.  \\n\",\n",
    "        \"- Citation activity increases across more recent 5-year bins, consistent with growth in publication volume.  \\n\",\n",
    "        \"\\n\",\n",
    "        \"You can refine this section later with concrete numbers and observations from your actual run.\\n\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"language\": \"python\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"name\": \"python\",\n",
    "      \"version\": \"3.11\"\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
